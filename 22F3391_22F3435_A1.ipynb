{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HANew2N8uKKk"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install sacrebleu jiwer\n",
        "!pip install pandas numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zxk2YPMSufD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "bWZLXiMK8c2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2d6214-c06c-4175-c7c3-224e740ea83c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/dataset\"\n",
        "import os\n",
        "\n",
        "for poet in os.listdir(base_path):\n",
        "    print(poet)\n"
      ],
      "metadata": {
        "id": "rm_Uowx7-1gR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401d9460-0523-41b1-aa88-bb7b95dc59d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "waseem-barelvi\n",
            "wali-mohammad-wali\n",
            "sahir-ludhianvi\n",
            "nazm-tabatabai\n",
            "parveen-shakir\n",
            "noon-meem-rashid\n",
            "nida-fazli\n",
            "naji-shakir\n",
            "naseer-turabi\n",
            "mohsin-naqvi\n",
            "mirza-ghalib\n",
            "jigar-moradabadi\n",
            "meer-taqi-meer\n",
            "kaifi-azmi\n",
            "javed-akhtar\n",
            "meer-anees\n",
            "jaan-nisar-akhtar\n",
            "jaun-eliya\n",
            "habib-jalib\n",
            "gulzar\n",
            "firaq-gorakhpuri\n",
            "faiz-ahmad-faiz\n",
            "fahmida-riaz\n",
            "dagh-dehlvi\n",
            "ameer-khusrau\n",
            "altaf-hussain-hali\n",
            "bahadur-shah-zafar\n",
            "akbar-allahabadi\n",
            "ahmad-faraz\n",
            "allama-iqbal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/dataset\"\n",
        "urdu_texts = []\n",
        "\n",
        "for poet in os.listdir(base_path):\n",
        "    ur_folder = os.path.join(base_path, poet, \"ur\")\n",
        "    if os.path.exists(ur_folder):\n",
        "        for file in os.listdir(ur_folder):\n",
        "            file_path = os.path.join(ur_folder, file)\n",
        "            if os.path.isfile(file_path):\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    text = f.read().strip()\n",
        "                    if text:\n",
        "                        urdu_texts.append(text)\n",
        "\n",
        "print(\"Total Urdu files collected:\", len(urdu_texts))\n",
        "print(\"Example Urdu text:\\n\", urdu_texts[:1])\n"
      ],
      "metadata": {
        "id": "JLd-d8RcCX6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_urdu(text):\n",
        "    # remove diacritics\n",
        "    diacritics = re.compile(r'[\\u064B-\\u0652]')\n",
        "    text = re.sub(diacritics, '', text)\n",
        "\n",
        "    # normalize characters (e.g. different forms of ya, heh)\n",
        "    text = text.replace('ي', 'ی').replace('ہ', 'ھ')\n",
        "\n",
        "    # remove non-Urdu characters (digits, english, punctuation)\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', ' ', text)\n",
        "\n",
        "    # remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# apply to all urdu texts\n",
        "cleaned_urdu = [clean_urdu(t) for t in urdu_texts]\n",
        "\n",
        "print(\"Before:\", urdu_texts[0][:])\n",
        "print(\"After:\", cleaned_urdu[0][:])\n"
      ],
      "metadata": {
        "id": "DTLPS-YfF9PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urdu_to_roman_map = {\n",
        "    'ا': 'a', 'آ': 'aa', 'ب': 'b', 'پ': 'p', 'ت': 't', 'ٹ': 'ṭ', 'ث': 's',\n",
        "    'ج': 'j', 'چ': 'ch', 'ح': 'h', 'خ': 'kh', 'د': 'd', 'ڈ': 'ḍ', 'ر': 'r',\n",
        "    'ڑ': 'ṛ', 'ز': 'z', 'س': 's', 'ش': 'sh', 'غ': 'gh', 'ف': 'f', 'ق': 'q',\n",
        "    'ک': 'k', 'گ': 'g', 'ل': 'l', 'م': 'm', 'ن': 'n', 'و': 'w', 'ہ': 'h',\n",
        "    'ھ': 'h', 'ء': '', 'ی': 'y', 'ے':'e', 'ئ':'i'\n",
        "}\n",
        "\n",
        "def urdu_to_roman(text):\n",
        "    return ''.join(urdu_to_roman_map.get(ch, ch) for ch in text)\n",
        "\n",
        "roman_texts = [urdu_to_roman(t) for t in cleaned_urdu]\n",
        "print(roman_texts)\n",
        "print(len(roman_texts))"
      ],
      "metadata": {
        "id": "OAOIU91eGL2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "import sentencepiece as spm\n",
        "import os\n"
      ],
      "metadata": {
        "id": "gMUhSCYmHAJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write all cleaned Urdu lines to one file\n",
        "with open(\"all_urdu.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in cleaned_urdu:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "# Write all Roman lines to one file\n",
        "with open(\"all_roman.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in roman_texts:\n",
        "        f.write(line + \"\\n\")\n"
      ],
      "metadata": {
        "id": "lz3FUJQGRArV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Urdu subword tokenizer\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input='all_urdu.txt',\n",
        "    model_prefix='urdu_bpe',\n",
        "    vocab_size=8000,\n",
        "    character_coverage=0.9995,\n",
        "    model_type='bpe'\n",
        ")\n",
        "\n",
        "# Train Roman subword tokenizer\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input='all_roman.txt',\n",
        "    model_prefix='roman_bpe',\n",
        "    vocab_size=8000,\n",
        "    character_coverage=1.0,\n",
        "    model_type='bpe'\n",
        ")\n"
      ],
      "metadata": {
        "id": "demYvD4rRE5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained models\n",
        "sp_urdu = spm.SentencePieceProcessor()\n",
        "sp_urdu.load('urdu_bpe.model')\n",
        "\n",
        "sp_roman = spm.SentencePieceProcessor()\n",
        "sp_roman.load('roman_bpe.model')\n",
        "\n",
        "# Convert texts to subword IDs\n",
        "urdu_ids = [sp_urdu.encode(line, out_type=int) for line in cleaned_urdu]\n",
        "roman_ids = [sp_roman.encode(line, out_type=int) for line in roman_texts]\n",
        "\n",
        "\n",
        "PAD_IDX = sp_urdu.pad_id()   # same for Urdu, SentencePiece uses the same special ids\n",
        "BOS_IDX = sp_urdu.bos_id()\n",
        "EOS_IDX = sp_urdu.eos_id()\n",
        "\n",
        "\n",
        "print(\"PAD:\", PAD_IDX, \"BOS:\", BOS_IDX, \"EOS:\", EOS_IDX)\n",
        "\n",
        "print(\"Example Urdu tokens:\", urdu_ids[0][:20])\n",
        "print(\"Example Roman tokens:\", roman_ids[0][:20])\n"
      ],
      "metadata": {
        "id": "3tOejgPfRbcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import sentencepiece as spm\n",
        "\n",
        "# ---------- Load SentencePiece Tokenizers ----------\n",
        "sp_urdu = spm.SentencePieceProcessor()\n",
        "sp_urdu.load(\"urdu_bpe.model\")\n",
        "\n",
        "sp_roman = spm.SentencePieceProcessor()\n",
        "sp_roman.load(\"roman_bpe.model\")\n",
        "\n",
        "# Vocabulary sizes from SentencePiece\n",
        "INPUT_DIM = sp_urdu.get_piece_size()    # Urdu vocab size\n",
        "OUTPUT_DIM = sp_roman.get_piece_size()  # Roman vocab size\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers=2, dropout=0.3,pad_idx=0):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=n_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if n_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        # hidden: [n_layers*2, batch, hidden_dim]\n",
        "\n",
        "        hidden = self._cat_directions(hidden)\n",
        "        cell = self._cat_directions(cell)\n",
        "\n",
        "        # hidden/cell: [n_layers, batch, hidden_dim*2]\n",
        "        return hidden, cell\n",
        "\n",
        "    def _cat_directions(self, h):\n",
        "        # [num_layers*2, batch, hidden_dim] -> [num_layers, batch, hidden_dim*2]\n",
        "        return torch.cat((h[0::2], h[1::2]), dim=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---------- Decoder ----------\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers=4, dropout=0.3,pad_idx=0):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim,\n",
        "            hidden_dim * 2,  # match encoder biLSTM output\n",
        "            num_layers=n_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if n_layers > 1 else 0\n",
        "        )\n",
        "        self.fc_out = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        input = input.unsqueeze(1)  # [batch, 1]\n",
        "        embedded = self.embedding(input)\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        prediction = self.fc_out(output.squeeze(1))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "\n",
        "# ---------- Seq2Seq ----------\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        trg_len = trg.size(1)\n",
        "        trg_vocab_size = self.decoder.fc_out.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        # 🔥 Fix: expand encoder states (2 layers → 4 layers for decoder)\n",
        "        if hidden.size(0) < self.decoder.lstm.num_layers:\n",
        "            factor = self.decoder.lstm.num_layers // hidden.size(0)\n",
        "            hidden = hidden.repeat(factor, 1, 1)\n",
        "            cell = cell.repeat(factor, 1, 1)\n",
        "\n",
        "        # First input to decoder is <sos>\n",
        "        input = trg[:, 0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[:, t, :] = output\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[:, t] if torch.rand(1).item() < teacher_forcing_ratio else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "EMB_DIM = 256\n",
        "HIDDEN_DIM = 512   # bigger model\n",
        "ENC_LAYERS = 2\n",
        "DEC_LAYERS = 4\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = Encoder(INPUT_DIM, EMB_DIM, HIDDEN_DIM, ENC_LAYERS, pad_idx=PAD_IDX)\n",
        "decoder = Decoder(OUTPUT_DIM, EMB_DIM, HIDDEN_DIM, DEC_LAYERS, pad_idx=PAD_IDX)\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "kAKOzn_iUTQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_ids, trg_ids, max_len=50):\n",
        "        self.src_ids = src_ids\n",
        "        self.trg_ids = trg_ids\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src_ids[idx]\n",
        "        trg = self.trg_ids[idx]\n",
        "\n",
        "        # pad to fixed length\n",
        "        src = src[:self.max_len] + [PAD_IDX] * (self.max_len - len(src))\n",
        "        trg = trg[:self.max_len] + [PAD_IDX] * (self.max_len - len(trg))\n",
        "\n",
        "\n",
        "        return torch.tensor(src), torch.tensor(trg)\n"
      ],
      "metadata": {
        "id": "bloOuNvY3baR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# assume urdu_ids and roman_ids are lists of tokenized sequences\n",
        "train_src, test_src, train_trg, test_trg = train_test_split(urdu_ids, roman_ids, test_size=0.25, random_state=42)\n",
        "train_src, val_src, train_trg, val_trg = train_test_split(train_src, train_trg, test_size=0.33, random_state=42)\n",
        "\n",
        "train_dataset = TranslationDataset(train_src, train_trg, max_len=50)\n",
        "val_dataset   = TranslationDataset(val_src, val_trg, max_len=50)\n",
        "test_dataset  = TranslationDataset(test_src, test_trg, max_len=50)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32)\n"
      ],
      "metadata": {
        "id": "2rAuZio_3fRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example Roman encoding:\", sp_roman.encode(\"kwiy aṭka hwa he pl shayd\", out_type=int, add_bos=True, add_eos=True))\n",
        "print(\"Decoded back:\", sp_roman.decode(sp_roman.encode(\"kwiy aṭka hwa he pl shayd\", out_type=int, add_bos=True, add_eos=True)))\n",
        "print(\"Urdu sample:\", cleaned_urdu[0])\n",
        "print(\"Urdu encoded:\", sp_urdu.encode(cleaned_urdu[0], out_type=int, add_bos=True, add_eos=True)[:40])\n"
      ],
      "metadata": {
        "id": "npt-59sSk6xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# def train(model, dataloader, optimizer, criterion, clip=1):\n",
        "#     model.train()\n",
        "#     epoch_loss = 0\n",
        "\n",
        "#     for src, trg in dataloader:\n",
        "#         src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         output = model(src, trg)   # [batch, trg_len, output_dim]\n",
        "\n",
        "#         # shift for loss (ignore sos token at t=0)\n",
        "#         output_dim = output.shape[-1]\n",
        "#         output = output[:,1:,:].reshape(-1, output_dim)\n",
        "#         trg = trg[:,1:].reshape(-1)\n",
        "\n",
        "#         loss = criterion(output, trg)\n",
        "#         loss.backward()\n",
        "\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "#         optimizer.step()\n",
        "\n",
        "#         epoch_loss += loss.item()\n",
        "\n",
        "#     return epoch_loss / len(dataloader)\n",
        "\n",
        "\n",
        "# def evaluate(model, dataloader, criterion):\n",
        "#     model.eval()\n",
        "#     epoch_loss = 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for src, trg in dataloader:\n",
        "#             src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "#             output = model(src, trg, 0)  # no teacher forcing in eval\n",
        "#             output_dim = output.shape[-1]\n",
        "#             output = output[:,1:,:].reshape(-1, output_dim)\n",
        "#             trg = trg[:,1:].reshape(-1)\n",
        "\n",
        "#             loss = criterion(output, trg)\n",
        "#             epoch_loss += loss.item()\n",
        "\n",
        "#     return epoch_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "2yRjR-pB3hcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for src, trg in loader:\n",
        "        src, trg = src.to(model.device), trg.to(model.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)   # output: [batch, trg_len, vocab_size]\n",
        "\n",
        "        # reshape for loss\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)  # ignore first token\n",
        "        trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient clipping (avoid exploding gradients)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader)\n"
      ],
      "metadata": {
        "id": "Q2T8dEOp5MsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, trg in loader:\n",
        "            src, trg = src.to(model.device), trg.to(model.device)\n",
        "\n",
        "            output = model(src, trg, teacher_forcing_ratio=0)  # no teacher forcing\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(loader)\n"
      ],
      "metadata": {
        "id": "P5UzxQgE5QWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32)\n"
      ],
      "metadata": {
        "id": "Fcfl7Tx35S1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# N_EPOCHS = 15\n",
        "\n",
        "\n",
        "# for epoch in range(N_EPOCHS):\n",
        "#     train_loss = train(model, train_loader, optimizer, criterion)\n",
        "#     val_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "#     print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.3f}, Val Loss = {val_loss:.3f}\")\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, n_epochs=80, patience=5):\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_model_state = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train_loss = train(model, train_loader, optimizer, criterion)\n",
        "        val_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "        print(f\"Epoch {epoch}: Train Loss = {train_loss:.3f}, Val Loss = {val_loss:.3f}\")\n",
        "\n",
        "        # save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # stop if no improvement\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"⏹️ Early stopping at epoch {epoch} (no improvement for {patience} epochs).\")\n",
        "            break\n",
        "\n",
        "    # restore best model\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        print(\"✅ Best model restored with val_loss =\", best_val_loss)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "emJErUuk3kgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, train_loader, val_loader, optimizer, criterion,\n",
        "                    n_epochs=80, patience=15)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z63ZAIdyQp-c",
        "outputId": "c998251c-e07f-4096-99c1-f6c96113c44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 8.461, Val Loss = 7.184\n",
            "Epoch 2: Train Loss = 6.659, Val Loss = 6.443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu jiwer\n"
      ],
      "metadata": {
        "id": "3AtKmmStFZ99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, src_tensor, sp_urdu, sp_roman, max_len=50):\n",
        "    model.eval()\n",
        "    src_tensor = src_tensor.unsqueeze(0).to(model.device)  # add batch dim\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "        # Expand hidden/cell to match decoder layers\n",
        "        if hidden.size(0) < model.decoder.lstm.num_layers:\n",
        "            factor = model.decoder.lstm.num_layers // hidden.size(0)\n",
        "            hidden = hidden.repeat(factor, 1, 1)\n",
        "            cell = cell.repeat(factor, 1, 1)\n",
        "\n",
        "        input = torch.tensor([sp_roman.bos_id()], device=model.device)  # <sos>\n",
        "        outputs = []\n",
        "        print(\"Urdu tokens:\", sp_urdu.encode(\"کوئی اٹکا ھوا ھے پل شاید\"))\n",
        "        print(\"Roman tokens:\", sp_roman.encode(\"kwiy aṭka hwa he pl shayd\"))\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            output, hidden, cell = model.decoder(input, hidden, cell)\n",
        "            top1 = output.argmax(1)\n",
        "            if top1.item() == sp_roman.eos_id():  # stop at <eos>\n",
        "                break\n",
        "            outputs.append(top1.item())\n",
        "            input = top1\n",
        "\n",
        "    return sp_roman.decode(outputs)\n"
      ],
      "metadata": {
        "id": "Txy-sDqfFh6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "from jiwer import cer\n",
        "\n",
        "def evaluate_metrics(model, src_texts, trg_texts, sp_urdu, sp_roman, n_samples=100):\n",
        "    preds, refs = [], []\n",
        "    for i in range(min(n_samples, len(src_texts))):\n",
        "        src_ids = torch.tensor(src_texts[i])\n",
        "        pred = translate_sentence(model, src_ids, sp_urdu, sp_roman)\n",
        "        tgt = sp_roman.decode(trg_texts[i])\n",
        "        preds.append(pred)\n",
        "        refs.append(tgt)\n",
        "\n",
        "    # BLEU\n",
        "    bleu = sacrebleu.corpus_bleu(preds, [refs]).score\n",
        "    # Perplexity (from validation loss)\n",
        "    val_loss = evaluate(model, val_loader, criterion)\n",
        "    perplexity = torch.exp(torch.tensor(val_loss)).item()\n",
        "    # CER\n",
        "    cer_score = cer(refs, preds)\n",
        "\n",
        "    print(f\"BLEU: {bleu:.2f}\")\n",
        "    print(f\"Perplexity: {perplexity:.2f}\")\n",
        "    print(f\"CER: {cer_score:.3f}\")\n",
        "\n",
        "    # Show some examples\n",
        "    for i in range(3):\n",
        "        print(\"\\nUrdu Input:   \", sp_urdu.decode(src_texts[i]))\n",
        "        print(\"Target Roman: \", refs[i])\n",
        "        print(\"Model Output: \", preds[i])\n"
      ],
      "metadata": {
        "id": "O-gDk7_vFl8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_metrics(model, val_src, val_trg, sp_urdu, sp_roman, n_samples=50)\n"
      ],
      "metadata": {
        "id": "Q9mbNKUIFnuE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}